--              Language Independent Runtime Library
--
--                     Copyright 1983-2014
--                  Green Hills Software,Inc.

--  This program is the property of Green Hills Software, Inc,
--  its contents are proprietary information and no part of it
--  is to be disclosed to anyone except employees of Green Hills
--  Software, Inc., or as agreed in writing signed by the President
--  of Green Hills Software, Inc.

#include "ind_800.h"

        .file "ccmemcpy.800"
        .text
        .align  2
..lxtdaG._memcpy=:0
	.weak  _memcpy
        .globl  _memcpy
#if __ghs_asm == 2
        .globl  _memcpy_mcopy
#endif
	-- r6 is the destination pointer
	-- r7 is the source pointer
	-- r8 holds the number of bytes to copy
	-- we return r6 in r10
	-- In 20 register mode, we cannot use r15-r24
	-- Because _mcopy saves all registers we use, we provide
	-- a separate entry point for it in case the user overrides 
	-- memcpy with their own implementation, so that _mcopy still uses
	-- a version that only affects the registers it was designed for
_memcpy:
_memcpy_mcopy:
    	mov	r6,r1
	andi	3,r6,r11
	bnz	bytesr6
	xor	r7,r11
	andi	3,r11,r11
	bnz	bytesr7
	-- r6 and r7 are aligned
	mov	r8,r14
	shr	4,r14
	bz	bytes
word_loop:
#ifdef __CORE_V850E3V5__
	ld.dw	0[r7],r10
	ld.dw	8[r7],r12
	add	16,r7
	st.dw	r10,0[r6]
	st.dw	r12,8[r6]
	add	16,r6
	loop	r14, word_loop
#else
	ld.w	0[r7],r10
	ld.w	4[r7],r11
	ld.w	8[r7],r12
	ld.w	12[r7],r13
	add	16,r7
	st.w	r10,0[r6]
	st.w	r11,4[r6]
	st.w	r12,8[r6]
	st.w	r13,12[r6]
	add	16,r6
	add	-1,r14
	bnz 	word_loop
#endif
	and	15,r8
	bnz	bytes
	mov	r1,r10
	jmp	[lp]
-- r6 is not aligned
bytesr6:
	mov	r7,r11
	mov	r8,r9
	subr	r0,r11
	and	3,r11
	-- r11 holds the number of bytes needed to align r7
	bz	alignedr6 -- r7 is already aligned
	-- check that we have enough bytes to copy to align r7
	sub	r11,r9
	bnh	bytes
.align 4
	-- loop aligns r7
small_loop_r6:
	ld.b	0[r7],r12
	add	1,r7
	st.b	r12,0[r6]
	add	1,r6
#ifdef __CORE_V850E3V5__
	loop 	r11, small_loop_r6
#else
	add	-1, r11
	bnz	small_loop_r6
#endif
alignedr6:
	-- now we will copy r7 4 bytes at a time
	mov	r9,r8
	-- 	Make sure we have enough bytes to copy 4-at-a-time
	shr	2,r9
	bz	bytes
.align 4
word_loop_r6:
	ld.w	0[r7],r10
	add	4,r7
	mov	r10,r11
	mov	r10,r12
	mov	r10,r13
	st.b	r10,0[r6]
	shr	8,r11
	st.b	r11,1[r6]
	shr	16,r12
	st.b	r12,2[r6]
	shr	24,r13
	st.b	r13,3[r6]
	add	4,r6
#ifdef __CORE_V850E3V5__
	loop 	r9, word_loop_r6
#else
	add	-1, r9
	bnz	word_loop_r6
#endif
	-- determine how many bytes are left to copy
	and	3,r8
	bnz	bytes
	mov	r1,r10
	jmp 	[lp]
bytesr7:
	-- r7 is not aligned, but if we get here r6 is aligned
	-- try copying to r6 four bytes at a time
	mov	r8,r9
	shr	2,r9
	bz	bytes	-- not enough bytes
.align 4
word_loop_r7:
#ifdef __CORE_V850E__
	ld.bu	0[r7], r10
	ld.bu	1[r7], r11
	ld.bu	2[r7], r12
	ld.bu	3[r7], r13
#else 
	-- Original V850
	ld.b	0[r7], r10
	ld.b	1[r7], r11
	ld.b	2[r7], r12
	ld.b	3[r7], r13
#endif
#ifdef __CORE_V850E3V5__
	bins	r11, 8, 8, r10
	bins	r12, 16, 8, r10
	bins	r13, 24, 8, r10
#else
#ifndef __CORE_V850E__
	-- Original V850
	andi	255,r10,r10
	andi	255,r11,r11
	andi	255,r12,r12
	andi	255,r13,r13
#endif
	shl	8,r11
	shl	16,r12
	shl	24,r13
	or	r11,r10
	or	r12,r10
	or	r13,r10
#endif
	add	4,r7
	st.w	r10,0[r6]
	add	4,r6
#ifdef __CORE_V850E3V5__
	loop 	r9, word_loop_r7
#else
	add	-1, r9
	bnz	word_loop_r7
#endif
	-- determine how many bytes are left to copy
	and	3,r8
	bnz	bytes
	mov	r1,r10
	jmp 	[lp]
-- Byte copy
bytes:
	cmp	zero,r8
	bz	end
.align 4
byte_loop:
	ld.b	0[r7],r11
	add	1,r7
	st.b	r11,0[r6]
	add	1,r6
#ifdef __CORE_V850E3V5__
	loop	r8, byte_loop
#else
	add	-1,r8
	bnz	byte_loop
#endif
end:
	mov 	r1,r10
	jmp	[lp]
	.fsize _memcpy,0
	.scall _memcpy,__leaf__
	.type _memcpy,@function
	.size _memcpy,.-_memcpy

	.global ___mcopy
..lxtdaG.___mcopy=:0
	-- Must preserve all registers (except lp obviously)
	-- r1, r6-r14 are used by memcpy
	-- The arguments are the same as memcpy except the source and dest are
	-- reversed, which we must preserve unfortuantely for backwards
	-- compatibility
___mcopy:
#ifdef __CORE_V850E3V5__
	pushsp	r1
	pushsp	r6-r14
	pushsp	lp
#else
	add	-44,sp
	st.w	r1, 0[sp]
	st.w	r6, 4[sp]
	st.w	r7, 8[sp]
	st.w	r8, 12[sp]
	st.w	r9, 16[sp]
	st.w	r10, 20[sp]
	st.w	r11, 24[sp]
	st.w	r12, 28[sp]
	st.w	r13, 32[sp]
	st.w	r14, 36[sp]
	st.w	lp, 40[sp]
#endif
	mov	r6, r9
	mov	r7, r6
	mov	r9, r7
	jarl	_memcpy_mcopy, lp
#ifdef __CORE_V850E3V5__
	popsp	lp
	popsp	r6-r14
	popsp	r1
#else
	ld.w	40[sp], lp 
	ld.w	0[sp], r1 
	ld.w	4[sp], r6 
	ld.w	8[sp], r7 
	ld.w	12[sp], r8 
	ld.w	16[sp], r9 
	ld.w	20[sp], r10
	ld.w	24[sp], r11
	ld.w	28[sp], r12
	ld.w	32[sp], r13
	ld.w	36[sp], r14
	add	44,sp
#endif
	jmp	[lp]
	.fsize 44
	.scall 	_memcpy_mcopy
	.type	___mcopy,@function
	.size	___mcopy,.-___mcopy
